@phdthesis{Thesis,
    title    = {Design, implementation and analysis of a
deep convolutional-recurrent neural network
for speech recognition through audiovisual
sensor fusion},
    school   = {KU LEUVEN},
    author   = {Matthijs Van keirsbilck},
    year     = {2016-2017}
}

@mastersthesis{mastersThesis,
    title    = {Building an end-to-end speech recognizer},
    school   = {KU LEUVEN},
    author   = {Moritz Wolter},
    year     = {2016-2017}
}

@misc{LIPNET,
Author = {Yannis M. Assael and Brendan Shillingford and Shimon Whiteson and Nando de Freitas},
Title = {LipNet: End-to-End Sentence-level Lipreading},
Year = {2016},
Eprint = {arXiv:1611.01599},
}

@inproceedings{LipreadingCNN,
title = "Lipreading using convolutional neural network",
keywords = "Convolutional neural network, Lipreading, Visual feature extraction",
author = "Kuniaki Noda and Yuki Yamaguchi and Kazuhiro Nakadai and Okuno, {Hiroshi G.} and Tetsuya Ogata",
year = "2014",
language = "English",
pages = "1149--1153",
booktitle = "Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",
publisher = "International Speech and Communication Association",
}

@misc{LipreadingInWild,
Author = {Joon Son Chung and Andrew Senior and Oriol Vinyals and Andrew Zisserman},
Title = {Lip Reading Sentences in the Wild},
Year = {2016},
Eprint = {arXiv:1611.05358},
}

@misc{LAS,
Author = {William Chan and Navdeep Jaitly and Quoc V. Le and Oriol Vinyals},
Title = {Listen, Attend and Spell},
Year = {2015},
Eprint = {arXiv:1508.01211},
}

@misc{Attention_Medium,
  author = {Zafarali Ahmed},
  title = {How to Visualize Your Recurrent Neural Network with Attention in Keras},
  year = {2017},
  note = {Last accessed 29 June 2017},
  url = {https://medium.com/datalogue/attention-in-keras-1892773a4f22}
} 

@misc{Attention_memory,
  author = {DENNY BRITZ},
  title = {Attention and Memory in Deep Learning and NLP},
  year = {2016},
  note = {Last accessed 3 Jan 2017},
  url = {http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/}
} 

@misc{LipreadingLSTM,
Author = {Michael Wand and Jan Koutník and Jürgen Schmidhuber},
Title = {Lipreading with Long Short-Term Memory},
Year = {2016},
Eprint = {arXiv:1601.08188},
}

@misc{Speech_Attention,
Author = {Jan Chorowski and Dzmitry Bahdanau and Dmitriy Serdyuk and Kyunghyun Cho and Yoshua Bengio},
Title = {Attention-Based Models for Speech Recognition},
Year = {2015},
Eprint = {arXiv:1506.07503},
}

@misc{Attention_ML,
  author = {Jason Brownlee},
  title = {How Does Attention Work in Encoder-Decoder Recurrent Neural Networks},
  year = {2017},
  note = {Last accessed 13 October 2017},
  url = {https://machinelearningmastery.com/how-does-attention-work-in-encoder-decoder-recurrent-neural-networks/}
} 

@misc{Attention_LSTM,
  author = {Jason Brownlee},
  title = {Attention in Long Short-Term Memory Recurrent Neural Networks},
  year = {2017},
  note = {Last accessed 30 June 2017},
  url = {https://machinelearningmastery.com/attention-long-short-term-memory-recurrent-neural-networks/}
}


@misc{LSTMParams,
  author = {Stack Exchange, Data Science},
  title = {Number of parameters in an LSTM model},
  year = {2016},
  url = {https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model}
} 

@misc{MultimodalMlReview,
  author = {ML Review},
  title = {Multi-Modal Methods: Visual Speech Recognition (Lip Reading)},
  year = {2018},
  url = {https://medium.com/mlreview/multi-modal-methods-part-one-49361832bc7e}
} 


https://github.com/rizkiarm/LipNet/blob/master/lipnet/model2.py

https://github.com/philipperemy/keras-attention-mechanism


@misc{SRattention,
Author = {Jan Chorowski and Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
Title = {End-to-end Continuous Speech Recognition using Attention-based Recurrent NN: First Results},
Year = {2014},
Eprint = {arXiv:1412.1602},
}

@article{bvjs15,
author = {S. Bengio and O. Vinyals and N. Jaitly and N. Shazeer},
journal = {In Advances in Neural Information Processing Systems},
pages = {1171-1179},
title = {Scheduled sampling for sequence prediction with recurrent neural networks},
year = {2015},
}

@article{cbscb15,
author = {J. K. Chorowski and D. Bahdanau and D. Serdyuk and K. Cho and Y. Bengio},
journal = {In Advances in Neural Information Processing Systems},
pages = {577-585},
title = {Attention-based models for speech recognition},
year = {2015},
}

@inproceedings{cz16,
author = {J. S. Chung and A. Zisserman},
booktitle = {Proc},
publisher = {ACCV},
title = {Lip reading in the wild},
year = {2016},
}

@article{gpm12,
author = {G. Galatas and G. Potamianos and F. Makedon},
journal = {In Signal Processing Conference (EUSIPCO)},
pages = {2714-2717},
title = {Audio-visual speech recognition incorporating facial depth information captured by the kinect},
volume = {2012},
year = {2012},
unidentified = {Proceedings of the 20th European, pages. IEEE},
}

@inproceedings{SRRNN,
author = {A. Graves and N. Jaitly},
booktitle = {Proceedings of the 31st International Conference on Machine Learning (ICML- 14},
pages = {1764-1772},
title = {Towards end-to-end speech recognition with recurrent neural networks},
year = {2014},
}

@article{LSTM,
author = {S. Hochreiter and J. Schmidhuber},
journal = {Neural computation},
number = {8},
pages = {1735-1780},
title = {Long short-term memory},
volume = {9},
year = {1997},
}

@article{Dlib,
author = {D. E. King},
journal = {The Journal of Machine Learning Research},
pages = {1755-1758},
title = {Dlib-ml: A machine learning toolkit},
volume = {10},
year = {2009},
}

@inproceedings{Mouthshapes,
author = {O. Koller and H. Ney and R. Bowden},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision Workshops},
pages = {85-91},
title = {Deep learning of mouth shapes for sign language},
year = {2015},
}

@article{Imagenet,
author = {A. Krizhevsky and I. Sutskever and G. E. Hinton},
journal = {In NIPS},
pages = {1106-1114},
title = {ImageNet classification with deep convolutional neural networks},
year = {2012},
}

@inproceedings{CNNFeatures,
author = {Y. Lan and R. Harvey and B. Theobald and E.-j. Ong and R. Bowden},
booktitle = {International Conference on Auditory-Visual Speech Processing 2009},
pages = {102-106},
title = {Comparing visual features for lipreading},
year = {2009},
}

@inproceedings{MultimodalAVSR,
address = {IEEE},
author = {Y. Mroueh and E. Marcheret and V. Goel},
booktitle = {2015 IEEE International Conference on Acoustics},
pages = {2130-2134},
publisher = {Speech and Signal Processing (ICASSP)},
title = {Deep multimodal learning for audio-visual speech recognition},
year = {2015},
}

@article{CNNLipreading,
author = {K. Noda and Y. Yamaguchi and K. Nakadai and H. G. Okuno and T. Ogata},
journal = {In INTERSPEECH},
pages = {1149-1153},
title = {Lipreading using convolutional neural network},
year = {2014},
}

@article{AVSR2,
author = {K. Noda and Y. Yamaguchi and K. Nakadai and H. G. Okuno and T. Ogata},
journal = {Applied Intelligence},
number = {4},
pages = {722-737},
title = {Audio-visual speech recognition using deep learning},
volume = {42},
year = {2015},
}

@article{sq2sq,
author = {I. Sutskever and O. Vinyals and Q. Le.},
journal = {In Advances in neural information processing systems},
pages = {3104-3112},
title = {Sequence to sequence learning with neural networks},
year = {2014},
}

@article{AVSR,
author = {S. Tamura and H. Ninomiya and N. Kitaoka and S. Osuga and Y. Iribe and K. Takeda and S. Hayamizu},
journal = {In},
pages = {575-582},
title = {Audio-visual speech recognition using deep bottleneck features and high-performance lipreading},
volume = {2015},
year = {2015},
unidentified = {Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA), pages. IEEE},
}

@article{speechDecoding,
author = {Z. Zhou and G. Zhao and X. Hong and M. Pietik¨ainen},
journal = {Image and vision computing},
number = {9},
pages = {590-605},
title = {A review of recent advances in visual speech decoding},
volume = {32},
year = {2014},
}

@article{choi2018visual,
  title={Visual Speech Recognition System with Deep Neural Networks},
  author={Choi, Jin Sol and Kim, Daeyeol and Cho, Sooyoung and Yoo, Sinwoo and Sohn, Chae-Bong},
  journal={International Journal of Applied Engineering Research},
  volume={13},
  number={15},
  pages={12073--12076},
  year={2018}
}

@techreport{garg2016lip,
  title={Lip reading using CNN and LSTM},
  institution={Stanford University},
  author={Garg, Amit and Noyola, Jonathan and Bagadia, Sameep},
  year={2016}
}

@article{DNNOverview,
Author = {Juergen Schmidhuber},
Title = {Deep Learning in Neural Networks: An Overview},
Year = {2014},
Eprint = {arXiv:1404.7828},
Howpublished = {Neural Networks, Vol 61, pp 85-117, Jan 2015},
Doi = {10.1016/j.neunet.2014.09.003},
}

@misc{BatchNormalization,
Author = {Sergey Ioffe and Christian Szegedy},
Title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
Year = {2015},
Eprint = {arXiv:1502.03167},
}

@misc{blendingLSTMCNN,
Author = {Krzysztof J. Geras and Abdel-rahman Mohamed and Rich Caruana and Gregor Urban and Shengjie Wang and Ozlem Aslan and Matthai Philipose and Matthew Richardson and Charles Sutton},
Title = {Blending LSTMs into CNNs},
Year = {2015},
Eprint = {arXiv:1511.06433},
}

@misc{SRusingDNN,
Author = {Ying Zhang and Mohammad Pezeshki and Philemon Brakel and Saizheng Zhang and Cesar Laurent Yoshua Bengio and Aaron Courville},
Title = {Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks},
Year = {2017},
Eprint = {arXiv:1701.02720},
}

